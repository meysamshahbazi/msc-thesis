% !TeX root=../main.tex
\chapter{نتایج}
%\thispagestyle{empty} 
\label{chap:results}
\section{مقدمه} 
در این فصل ابتدا ملاحظات پیاده‌سازی روش پیشنهادی بیان می‌شود. سپس معیارهای ارزیابی که در پژوهش‌ها برای توصیف میزان دقت شبکه وجود دارد تعریف می‌گردد. و در ادامه ابتدا هر قسمت از روش‌های پیشنهادی روی یک دیتاست کوچک اجرا می‌گردد تا میزان تأثیر هر روش به تنهایی مشخص گردد. در انتها از تمام روش پیشنهادی برای دیتاست‌های بزرگ‌تر استفاده شده و دقت‌های به‌دست آمده با دقت روش‌های موجود در این حوزه مقایسه شود.
\section{ملاحظات پیاده‌سازی}
در این پایان‌نامه از زبان برنامه‌نویسی پایتون و کتابخانه \lr{Pytorch} استفاده شده است. این کتابخانه ابزاری قدرتمند برای مدل‌سازی شبکه‌های عمیق است. از آنجا که \lr{Pytorch} انعطاف‌پذیری بیشتری نسبت به ابزارهای مشابه دارد، پیاده‌سازی توابع جدید و عملگرهای غیر متداول در آن راحت‌تر است. در این پایان‌نامه یک عملگر جدید \lr{LBP} و تابع هزینه‌ی خاصی معرفی شده است که مشابه آن در ابزارهای یادگیری عمیق به‌صورت ماژول آماده وجود ندارد؛ اما توسط جریان محاسباتی \lr{Pytorch} قابل پیاده سازی است. 
\subsection{پیاده سازی \lr{LBP} قابل آموزش}
برای پیاده‌سازی یک عملگر جدید که دارای پارامتر قابل یادگیری باشد لازم است که یک کلاس با ارث‌بری از \lr{nn.Module} نوشته شود. با این‌کار این کلاس دارای قابلیت \lr{forward} و \lr{backward} خواهد بود و قابل استفاده در جریان محاسباتی شبکه عمیق خواهد بود.
برای آنکه این کلاس دارای پارامترهای یادگیرنده باشد لازم است که متغیر پارامترهای کلاس با استفاده از \lr{nn.Parameter} نوشته شود. با این کار در صورت استفاده از این عملگر به‌عنوان یک لایه در شبکه، پارامترهای عملگر \lr{LBP} در میان پارامترهای شبکه قرار می‌گیرند و بهینه‌سازی، منجر به به‌روزرسانی این پارامترها خواهد شد.
\subsection{پیاده‌سازی تابع هزینه}
در هر بار \lr{forward} داده‌ها به شبکه پس از بلوک استخراج ویژگی یک بردار به‌دست خواهد آمد که لازم است این بردار در هر مرحله برای استفاده در دو تابع هزینه معرفی شده نرمالایز شوند. در حین تست شبکه از آنجا که تغییری در وزن‌ها رخ نخواهد داد یک بار نرمال‌سازی کافی خواهد بود. پیاده‌سازی تابع \lr{َARCB} با استفاده از توابع \lr{Pytorch} برای پایدار بودن محاسبات انجام شده است. به‌منظور جلوگیری از بیش برازش داده‌ها از \lr{drop out}
\cite{srivastava2014dropout}
در لایه آخر پس از نرمالایز کردن بردار ویژگی و پیش از طبقه‌بند استفاده شده است. 
برای پیاده سازی تابع هزینه مبتنی بر شناسه اشخاص نیاز است به غیر از تصویر ورودی و برچسب تصویر، یک عدد به‌عنوان شناسه نیز در اختیار باشد. در دیتاست‌های موجود یافتن عدد شناسه از روی نام فایل ویدئو قابل تشخیص است. برای بهینه‌سازی شبکه از الگوریتم آدام 
\cite{kingma2014adam}
استفاده شده است.
\subsection{بارگذاری داده‌ها برای آموزش}
برای بارگذاری و آماده سازی داده‌ها توابع و کلاس‌های آماده در کتابخانه \lr{Pythoch} وجود دارد که به‌صورت خودکار تصاویر موجود در یک پوشه استفاده خواهد کرد اما به‌دلیل ماهیت ویدیویی داده‌ها و همچنین تابع هزینه خاص معرفی شده نمی‌توان از توابع آماده استفاده کرد.
در برخی دیتاست‌ها فایلی برای مختصات چهره وجود دارد که می‌توان در هر فریم ویدئو، قسمت مربوط به چهره را برش زد و به‌جای استفاده از کل فریم تنها قسمت چهره به همراه کمی از قسمت پس‌زمینه تصویر به‌عنوان ورودی به شبکه داده شود. در دیتاست‌هایی که این فایل مختصات وجود ندارد با استفاده از روش \lr{MTCCN}
\cite{zhang2016joint}
 چهره فریم‌ها پیدا شده و در یک فایل متنی ذخیره شده است.
دیتاست‌های معرفی شده همگی به‌صورت ویدئو هستند. از آنجا که روش ارائه شده روی تک تصویر کار می‌کند یکی از نکات عملی در خصوص آموزش روی داده‌های ویدیویی، نحوه آماده سازی داده‌ها برای آموزش است. یک روش تبدیل ویدئو به تصویر و ذخیره آن روی دیسک است. اما این کار موجب مصرف شده حجم زیادی از دیسک خواهد شد و از آنجا که در حین آموزش لازم است که تصاویر مجدداً از دیسک به حافظه \lr{RAM} بارگذاری شوند روال آموزش کند خواهد شد.
از طرفی از آنجا که نمونه‌های موجود در دو کلاس با یک دیگر برابر نیستند به‌منظور پایدار شدن تابع هزینه \lr{ARCB} لازم است که در هر دسته به تعداد نزدیک هم ویدئو از هر کلاس وجود داشته باشد. از طرفی برای آنکه تابع هزینه مبتنی بر شناسه اشخاص به‌درستی عمل کند لازم است که پراکندگی ویدیوها در هر دسته به‌اندازه کافی باشد تا حالت‌های مختلف از اشخاص با شناسه‌های متفاوت و برچسب متفاوت در دسته وجود داشته باشد. همچنین لازم است که ترتیب داده‌ها تا حد ممکن تصادفی باشند تا غیر یقینی بیشتری در حین آموزش، برای شبکه وجود داشته باشد. 
در پیاده‌سازی روش این پایان‌نامه ابتدا به تعداد دسته، ویدئو در حافظه \lr{RAM} بارگذاری خواهد شد و در هر مرحله یک فریم به‌صورت رندوم از هر ویدئو انتخاب داده می‌شود که در نهایت به تعداد دسته، فریم برای آموزش وجود خواهد داشت. در مراحل بعدی از همین ویدیوها که در حافظه \lr{RAM} بارگذاری شده‌اند استفاده خواهد شد و این روال تا زمانی که فریم در ویدیوها وجود داشته باشد ادامه خواهد داشت. سپس دسته ویدئو دیگری انتخاب خواهد شد و آموزش روی همه ویدیوها ادامه خواهد داشت. 
از آنجا که پس از انتخاب تعدادی ویدئو، به تعداد فریم‌های آن و به‌صورت متوالی مرحله‌های آموزش تکرار می‌شود و فریم‌های متوالی یک ویدئو از نظر ظاهری نزدیک به هم هستند لازم است که غیر یقینی داده‌ها بیشتر شود بدین منظور از روش‌های افزایش داده 1به‌صورت تصادفی استفاده می‌شود. بدین منظور از تبدیلاتی که هر تصویر ورودی را به‌صورت تصادفی چرخش می‌دهند استفاده می‌شود. 
به‌منظور جلوگیری از بیش برازش از روش پاک کردن تصادفی قسمتی از تصویر ورودی استفاده شده است 
\cite{zhong2020random}
. همچنین هنگامی که قرار است قسمت چهره به همراه پس زمینه برش زده شود این کار به‌صورت یک پنجره تصادفی انجام می‌شود؛ بدین ترتیب در هر بار بارگذاری داده‌ها موقعیت چهره در تصویر برش زده تصادفی خواهد بود و لزوماً همیشه در مرکز تصویر نخواهد بود.
در شکل  
\ref{fig:aug}
نحوه برش زدن تصادفی چهره به همراه پس زمینه نشان داده شده است. در این تصویر مستطیل آبی چهره فرد را نشان می‌دهد و مستطیل‌های رنگی به‌صورت تصادفی برای هر بار انتخاب چهره انتخاب می‌شوند. 
\begin{figure}[ht]
	\centerline{\includegraphics[width=0.5\linewidth]{aug}}
	\caption{نحوه برش زدن تصادفی چهره با مقداری از پس‌زمینه}
	\label{fig:aug}
\end{figure}

برای پیاده سازی کلاس بارگذاری داده یک
 \lr{data loader} 
سفارشی نوشته شده است و همچنین برای آنکه استراتژی ترتیب تصادفی انتخاب ویدئو و استفاده مجدد از فریم‌های ویدئو متوالی پیاده شود یک تابع batch sampler سفارشی نوشته شده است. در پیاده سازی این تابع از مفهوم \lr{iteration} در زبان برنامه نویسی پایتون استفاده شده است.
\section{معیارهای ارزیابی}
مسئله کشف تقلب یک مسئله طبقه‌بندی دو کلاسه است که در هنگام آزمون، معمولاً تعداد نمونه‌های واقعی و تقلبی یکسان نیستند. به همین دلیل معیار دقت شبکه یعنی تعداد نمونه‌های درست پیش‌بینی شده تقسیم بر تعداد کل نمونه‌ها ملاک خوبی برای قضاوت در مورد عملکرد شبکه نیست. 

بدین منظور از معیاری به نام نرخ خطای برابر و ترسیم آن به ازای آستانه‌های مختلف، در قالب نمودار نرخ خطای برابر استفاده می‌شود. 
دو حالت برای تشکیل این نمودار مهم است. نرخ خطای قبول کردن1 نمونه، که به معنی این است که برچسب واقعی چهره زنده بوده است اما به‌عنوان چهره تقلبی پیش‌بینی شده است. و نرخ خطای رد کردن2 که به معنی این است که نمونه برچسب تقلبی دارد ولی به‌عنوان چهره زنده پیش‌بینی شده است.
\begin{equation} \label{eq:far}
	FAR = \frac{number of false accepted samples}{total number of fake samples}
\end{equation}
\begin{equation} \label{eq:frr}
	FAR = \frac{number of false rejected samples}{total number of real samples}
\end{equation}

معمولاً این مقدار بر اساس یک آستانه که یکی از یک پارامتر است محاسبه می‌گردد. برای مثال در شبکه‌ی عصبی مقدار تک نورون لایه آخر با تابع فعالسازی سیگموید، مقداری بین صفر و یک خواهد داشت. و با انتخاب یک سطح آستانه و مقایسه مقدار نورون لایه‌ی آخر با این سطح آستانه تصمیم‌گیری در مورد پیش‌بینی برچسب نمونه انجام می‌شود. نرخ خطای برابر برابر با مقداری است که $FAR$ با $FRR$ برابر شود.

\begin{equation}\label{eq:taueer}
	\tau_{EER} = \argmin_{\tau}|FAR(\tau)-FRR(\tau)|
\end{equation}
\begin{equation}\label{eq:eer}
	EER=FAR(\tau_{EER})=FRR(\tau_{EER})
\end{equation}

در شکل
\ref{fig:eer}
این معیار را در قالب نمودار به ازای سطوح مختلف آستانه نشان می‌دهد. در دیتاست‌هایی که داده دارای سه قسمت آموزش، توسعه و آزمون است، معمولاً روی داده‌های آموزش وزن‌های شبکه به‌دست می‌آید و روی قسمت توسعه، پارامتر   به دست خواهد آمد. و روی قسمت آزمون معیار نصف کل نرخ خطا1 به‌صورت رابطه
\ref{eq:hter}
تعریف می‌شود.

\begin{equation}\label{eq:hter}
	HTER=\frac{FAR(\tau_{EER})+FRR(\tau_{EER})}{2}
\end{equation}

 \begin{figure}[ht]
	\centerline{\includegraphics[width=0.5\linewidth]{eer}}
	\caption{نمودار میزان خطای برابر}
	\label{fig:eer}
\end{figure}

با تحلیل نمودار نرخ خطای برابر، می‌توان در مورد میزان عملکرد شبکه بحث کرد. هر چه که مقدار تقاطع منحنی \lr{FRR} و \lr{FAR} پایین‌تر باشد، شبکه دقت بهتری دارد. همچنین مقدار \lr{FRR} و \lr{FAR} در نزدیکی‌های محل تقاطع نشان می‌دهد که شبکه چه میزان دو کلاس را از هم جدا کرده است.

یک معیار دیگر برای ارزیابی استفاده از استاندارد
 \lr{ISO/IEC 30107-3} 
است که در آن از نرخ خطای طبقه‌بندی ارائه حمله 1 (\lr{APCER}) و نرخ خطای طبقه بندی ارائه خوب2 (\lr{BPCER}) تعریف می‌شود که در آن \lr{BPCER} معادل \lr{FRR} است ولی \lr{APCER} معادل بیشترین \lr{FAR} به ازای ابزارهای حمله مختلف است.
منظور از ابزار حمله، حمله کاغذ چاپ‌شده یا حمله بازپخش است. همچنین متوسط نرخ خطای طبقه‌بندی به‌صورت میانگین \lr{APCER} و \lr{BPCER} تعریف می‌شود.
\begin{equation}\label{eq:apcer}
	APCER=\max_{PAI=1,...,C}{FAR_{PAI}}
\end{equation}
\begin{equation}\label{eq:ACER}
	ACER=\frac{APCER+BPCER}{2}
\end{equation}
\section{عملکرد مدل در دیتاست‌ها}
این بخش به بررسی دقت روش پیشنهادی روی دیتاست‌های مختلف می‌پردازد. در ابتدا برای بررسی اثر بخشی روش پیشنهادی روی دیتاست \lr{Replay} که دیتاست نسبتاً کوچکی است، روش پیشنهادی بررسی می‌شود. این کار با هدف اثبات مفهوم1 انجام می‌شود. و سپس روی دیتاست‌های دیگر دقت گزارش می‌شود.
\subsection{اثر عملگر \lr{LBP} قابل آموزش در دیتاست \lr{Replay}}
به‌منظور مقایسه‌ی روش‌های پیشنهادی و تأثیر آنها در بهبود دقت ابتدا یک شبکه \lr{ALEXNET} بدون عملگر \lr{LBP} با تابع هزینه \lr{BCE} به کار برده می‌شود. نمودار نرخ خطای برابر، برای این مورد به‌صورت شکل 
\ref{fig:eer-alex-bce} 
است. همانطور که مشاهده می‌شود با در نظر گرفتن سطح آستانه 0.13 برای نورون آخر به خطای 7.3 درصد روی داده دیده نشده می‌رسیم. اما لازم است توجه شود تنها مقدار خطا مهم نیست و عملکرد نمودار در سایر نقاط سطح آستانه نیز مهم است و در سطح آستانه 0.6 مقدار خطا \lr{FRR} حدود 80 درصد است که بسیار زیاد است. همچنین در اطراف سطح آستانه 0.13 با کمی تغییر در سطح آستانه مقدار خطا بزرگ می‌شود.
\begin{figure}[h]
	\centerline{\includegraphics[width=0.5\linewidth]{eer-alex-bce}}
	\caption{نمودار خطای برابر برای شبکه \lr{ALEXNET} و تابع هزینه \lr{BCE}}
	\label{fig:eer-alex-bce}
\end{figure}

با استفاده از عملگر \lr{LBP} قابل آموزش پیش از \lr{ALEXNET} و تابع هزینه نیز کماکان \lr{BCE} باشد نمودار شکل
\ref{fig:eer-lbp}
به‌دست می‌آید.
\begin{figure}[h]
	\centerline{\includegraphics[width=0.5\linewidth]{eer-lbp}}
	\caption{نمودار خطای برابر هنگام استفاده از عملگر \lr{LBP} پیشنهادی}
	\label{fig:eer-lbp}
\end{figure}
همانطور که مشاهده می‌شود استفاده از تنها یک لایه 
\lr{LBP}
 پیش از \lr{ALEXNET} مقدار خطا را به صفر درصد رسانده است. همچنین وضعیت خطا در اطراف آستانه نیز بهبود یافته است.
از آنجا که افزودن یک لایه عملگر \lr{LBP} قابل آموزش کمی محاسبات به شبکه اضافه می‌کند برای مقایسه دیگر نمودار آموزش شبکه با تابع هزینه \lr{BCE} و شبکه
 \lr{efficient net B0} 
به صورت شکل 
\ref{fig:eer-eff}

است.
\begin{figure}[h]
	\centerline{\includegraphics[width=0.5\linewidth]{eer-eff}}
	\caption{نمودار خطای برابر هنگام استفاده از شبکه \lr{efficient net B0}}
	\label{fig:eer-eff}
\end{figure}

این نمودار نشان می‌دهد لزوماً استفاده از شبکه پیچیده نمی‌تواند به نتیجه مطلوب برساند. 
لازم است توجه شود این نمودار بدین معنی نیست که لایه \lr{LBP} به همراه \lr{ALEXNET} قدرت بیشتری نسبت به شبکه \lr{Efficient net} دارد. بلکه در این کاربرد خاص و دیتاست \lr{Replay} که حجم داده کمی دان‌هااستفاده از شبکه ساده‌تر اما هوشمندانه با توجه به مسئله، دقت بهتری را ایجاد می‌کند.
\subsection{اثر تابع هزینه \lr{ARCB} در دیتاست \lr{Replay}}
اکنون تنها از شبکه \lr{ALEXNET} بدون عملگر \lr{LBP} استفاده می‌شود ولی تابع هزینه \lr{ARCB} معرفی شده به‌جای تابع \lr{BCE} استفاده می‌شود. نمودار شکل
\ref{fig:eer-arcb}
نشان می‌دهد تغییر تابع هزینه بدون تغییری در ساختار می‌تواند تاثیرگذار باشد. نمودار در مقایسه با نمودارهای قبلی متقارن‌تر شده است. در این شکل میزان خطا در اطراف سطح آستانه صفر است ولی با دور شدن از سطح آستانه و نزدیک شدن به مقدار 0 و 1 خطا بیشتر می‌شود. این تأثیر حاشیه در تابع هزینه \lr{ARCB} است که موجب شده است دو کلاس با یک حاشیه از یک دیگر جدا شوند.

\begin{figure}[h]
	\centerline{\includegraphics[width=0.5\linewidth]{eer-arcb}}
	\caption{نمودار خطای برابر هنگام استفاده از تابع هزینه \lr{ARCB} پیشنهادی}
	\label{fig:eer-arcb}
\end{figure}

\subsection{اثر تابع هزینه بر پایه شناسه‌ی اشخاص در دیتاست \lr{Replay}}
اکنون از ساختار ساده \lr{ALEXNET} استفاده می‌شود و تابع هزینه برای طبقه بند تابع \lr{BCE} است ولی تابع هزینه مبتنی بر شناسه اشخاص نیز به آن افزوده شده است. نمودار این حالت به‌صورت شکل 
\ref{fig:eer-pid}
است. همانطور که مشاهده می‌شود خطا در آستانه‌های 0 تا 0.8 به‌صورت مطلق صفر است. که نشان می‌دهد دو کلاس با حاشیه مناسبی از هم جدا شده‌اند. تا این قسمت اثر هر کدام از روش‌های پیشنهادی به تنهایی بررسی شده‌اند. برای ادامه فصل تمامی روش‌ها در کنار یک‌دیگر استفاده می‌شود. و شبکه استخراج ویژگی \lr{Efficient net} است. همچنین به‌منظور تسریع در همگرا شدن شبکه، قسمت استخراج ویژگی از وزن‌های آموزش دیده روی دیتاست \lr{image-ne}t استفاده می‌شود ولی این وزن‌ها حین آموزش تغییر می‌کند.
\begin{figure}[h]
	\centerline{\includegraphics[width=0.5\linewidth]{eer-pid}}
	\caption{نمودار خطای برابر با استفاده از تابع هزینه مبتنی بر شناسه اشخاص}
	\label{fig:eer-pid}
\end{figure}

\subsection{نتایج روی دیتاست‌های \lr{CASIA} و \lr{MSU}}
دیتاست‌های \lr{MSU} و \lr{CASIA} نسبت به دیتاست \lr{Replay} دارای رزولوشن تصویر بیشتری هستند. این دیتاست‌ها بر خلاف دیتاست \lr{replay} که دارای سه قسمت آموزش، توسعه و آزمون است تنها دارای دو قسمت آموزش و آزمون می‌باشد. در جدول
\ref{tab:eercasiamsu}
 مقدار نرخ خطای برابر در قسمت آزمون دیتاست گزارش شده است.
\begin{table}[ht]
	\caption{خطای برابر روی دیتاست‌های \lr{CASI‌A} و ‌\lr{MSU}}
	\label{tab:eercasiamsu}
	\centering
	\onehalfspacing
	\begin{tabular}{|c|c|}
		\hline \lr{Dataset} &\lr{ EER (\%)}   \\
		\hline \lr{CASIA}   & \lr{0.54}     \\
		\hline \lr{MSU}     & \lr{0.0} \\
		   \hline
	\end{tabular} 
\end{table}

از آنجا که این دو دیتاست کمی قدیمی هستند رسیدن به نرخ خطای صفر چندان دشوار نیست. در پژوهش‌های اخیر در این حوزه، عمده گزارش‌های دقت روی دیتاست‌های \lr{SIW} و \lr{OULU} است. این دو دیتاست نسبت به دیتاست‌های قبلی جدیدتر و دارای حجم بیشتری هستند. به همین دلیل در پژوهش‌های اخیر بیشتر از این دو دیتاست استفاده شده است. هر کدام از این دو دیتاست دارای پروتکل‌های مختلفی هستند که حالت‌های مختلف برای بررسی تعمیم‌پذیری مدل را نشان می‌دهد.
\subsection{دقت در دیتاست \lr{SIW}}
در پروتکل اول دیتاست \lr{SIW} به بررسی تغییر حالت چهره می‌پردازد. بدین منظور برای آموزش از 60 فریم اول هر ویدئو استفاده می‌شود ولی برای تست از تمامی فریم‌های ویدیوهای تست استفاده می‌شود. از آنجا که در فریم­های ابتدایی هر ویدئو، کاربر صورت خود را تکان نمی‌دهد پس داده‌های آموزش تنها شامل تصاویر صورت با موقعیت ثابت در مقابل دوربین است. ولی داده‌های تست شامل همه حالت‌های حرکت چهره در ویدئو است. این پروتکل قابلیت تعمیم‌پذیری مدل ارائه شده را در حالت‌های مختلف چهره نشان می‌دهد. نتایج این حالت در جدول
\ref{tab:siw1}
همراه با مقایسه با برخی روش‌های معروف ذکر شده است.
\begin{table}[ht]
	\caption{نرخ در پروتکل اول دیتاست \lr{SIW}}
	\label{tab:siw1}
	\centering
	\onehalfspacing
	\begin{tabular}{|c|c|c|c|c|}
	\hline ACER & BPCER & APCER & Method                \\
	\hline 3.58 & 3.58  & 3.58  & Auxiliary {[}20{]}   \\
	\hline 0.25 & 0.50  & 0     & LGSC {[}14{]}          \\
	\hline 1    & -     & -     & STASN {[}25{]}       \\
	\hline 0.12 & 0.17  & 0.07  & CDCN {[}8{]}            \\
	\hline 0.4  & 0.17  & 0.64  & SGTD 				{[}24{]}      \\
	\hline 0.4  & 0.17  & 0.69  & 3DPC-NET 				{[}28{]}   \\
	\hline 0.13 & 0.12  & 0.14  & ARCB+PID    \\ 
	 \hline         
	\end{tabular}
\end{table}

در پروتکل دوم از چهار نوع حمله‌ی بازپخش، هر بار یک حمله برای تست کنار گذاشته می‌شود و آموزش شبکه روی سه حمله‌ی بازپخش دیگر انجام می‌شود. پس برای این پروتکل چهار حالت مختلف وجود دارد که میانگین و واریانس دقت روی چهار حالت گزارش می‌شود. این پروتکل با هدف بررسی عمکرد روش پیشنهادی روی نوع حمله بازپخش دیده نشده طراحی شده است. نتایج در جدول 

\ref{tab:siw1}
گزارش شده است.
\begin{table}[ht]
	\caption{نرخ در پروتکل دوم دیتاست \lr{SIW}}
	\label{tab:siw2}
	\centering
	\onehalfspacing
	\begin{tabular}{|c|c|c|c|c|}
		\hline ACER          & BPCER       & APCER         & Method                &  \\
		\hline 0.57 ±0.69    & 0.57 ±0.69  & 0.57 ±0.69    & Auxiliary {[}20{]}    &  \\
		\hline 0±0           & 0±0         & 0±0           & LGSC {[}14{]}         &  \\
		\hline 0.28±0.05     & -           & -             & STASN {[}25{]}        &  \\
		\hline 0.04±0.5      & 0±0.09      & 0±0           & CDCN {[}8{]}          &  \\
		\hline 0.02±0.04     & 0.04±0.08   & 0.0±0.0       & SGTD 				{[}24{]}     &  \\
		\hline 0.45±0.14     & 0.43±0.06   & 0.46±0.28     & 3DPC-NET 				{[}28{]} &  \\
		0.0087±0.0151 & 0.01±0.0173 & 0.0075±0.0129 & ARCB+PID              &  \\
		\hline         
	\end{tabular}
\end{table}

\subsection{دقت در دیتاست \lr{OULU}}
دیتاست \lr{OULU} نیز دارای چهار پروتکل مختلف است که در این پایان‌نامه دقت روی پروتکل اول و دوم گزارش شده است. 
دیتاست \lr{OULU} در سه مکان مختلف تصویر برداری شده است. در پروتکل اول روی ویدیوهای مربوط به مکان اول و دوم آموزش صورت می‌گیرد و در ویدیوهای مکان سوم تست انجام می‌گیرد. این پروتکل با این هدف ارائه شده است که قابلیت روش پیشنهادی با تغییر مکان تصویربرداری ارزیابی شود. 
در پروتکل دوم از دو حمله کاغذ چاپ شده و دو حمله بازپخش موجود در دیتاست یک حمله چاپ و یک حمله بازپخش برای آموزش و حمله چاپ و بازپخش دیگر برای تست استفاده می‌شود. هدف این پروتکل ارزیابی ابزار حمله دیده نشده در آموزش است. نتایج مربوط به دقت مدل ارائه شده در جدول
\ref{tab:oulu}
در پروتکل اول و دوم گزارش شده است.
\begin{table}[ht]
	\caption{دقت در پروتکل‌های اول و دوم دیتاست \lr{OULU}}
	\label{tab:oulu}
	\centering
	\onehalfspacing
	\begin{tabular}{lllllll}
     & Protocol 				1 &       &      & Protocol 				2 &       &                         \\
ACER & BPCER          & APCER & ACER & BPCER          & APCER & Method                  \\
5.7  & 8.9            & 2.5   & 1.9  & 1.3            & 2.5   & GFA 				{[}15{]}        \\
1.6  & 1.6            & 1.6   & 2.7  & 2.7            & 2.7   & Auxiliary 				{[}20{]}  \\
1.5  & 1.7            & 1.2   & 4.3  & 4.4            & 4.2   & FaceDs 				{[}16{]}     \\
0.4  & 0              & 0.8   & 0.7  & 0.6            & 0.8   & LGSC 				{[}14{]}       \\
1.9  & 2.5            & 1.2   & 2.2  & 0.3            & 4.2   & STASN 				{[}25{]}      \\
0.2  & 0              & 0.4   & 1.3  & 0.8            & 1.8   & CDCN 				{[}8{]}        \\
1.0  & 0.0            & 2.0   & 1.9  & 1.3            & 2.5   & SGTD 				{[}24{]}       \\
0.42 & 0              & 0.83  & 6.0  & 0.6            & 11.4  & DeepPixBis 				{[}26{]} \\
1.1  & 1.3            & 0.8   & 1.9  & 1.6            & 2.3   & STDN 				{[}17{]}       \\
1.2  & 0              & 2.3   & 3.0  & 2.8            & 3.1   & 3DPC-NET 				{[}28{]}   \\
2.29 & 2              & 2.58  & 0.97 & 0.97           & 0.97  & ARCB+PID \\              
		\hline         
	\end{tabular}
\end{table}

\subsection{نتایج روی آزمون بین دیتاست}
هماویدیویی در قسمت‌های قبلی مشاهده شده است با روش‌های جدید یادگیری عمیق، رسیدن به نرخ خطای نزدیک صفر، دور از انتظار نیست. اما نحوه عملکرد مدل ارائه شده روی داده‌های دیده نشده با توزیع متفاوت همچنان موضوع چالشی و مهم در تحقیقات دانشگاهی است. یک مدل ممکن است روی یک دیتاست با توزیع خاص به دقت بسیار بالایی برسد ولی هنگام استفاده از این مدل در دنیای واقعی، ضعیف عمل کند.
نتایج ارائه شده تا اینجا دقت مدل درون دیتاست بوده است. یکی دیگر از مسائل مهم در حوزه کشف تقلب، بررسی دقت در تست بین دو دیتاست مختلف است. بدین منظور مدل روی یک دیتاست آموزش داده می‌شود و روی دیتاست دیگر تست می‌شود. 
برای بررسی دقت مدل در تست بین دیتاست، شبکه روی دیتاست \lr{CASIA} آموزش داده شده است و روی دیتاست \lr{Replay} تست شده است. نتایج این حالت در جدول
\cite{tab:cross}

به همراه دقت پژوهش‌های دیگر گزارش شده است. 
\begin{table}[ht]
	\caption{تایج روی آزمون بین دیتاست}
	\label{tab:cross}
	\centering
	\onehalfspacing
	\begin{tabular}{|c|c|}
		& Method                  \\
		\lr{31.5} & STASN 				{[}25{]}      \\
		17   & SGTD 				{[}24{]}      \\
		27.6 & Auxiliary 				{[}20{]}   \\
		28.5 & FaceDs 				{[}16{]}     \\
		21.4 & GFA 				{[}15{]}       \\
		27.4 & LGSC 				{[}14{]}      \\
	\end{tabular}
\end{table}
با مقایسه نتایج دقت در آزمون بین دیتاست و درون دیتاست تفاوت قابل ملاحظه خطا، دیده می‌شود.





